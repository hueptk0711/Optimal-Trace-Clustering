{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12453500,"sourceType":"datasetVersion","datasetId":7855739}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import train_test_split\nimport glob\nimport os\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\ndef train_neural_network(df):\n    \"\"\"Train a neural network to predict the best clustering combination.\"\"\"\n    print(\"Training neural network...\")\n    \n    # Assign quality labels\n    def assign_quality_dynamic(silhouette):\n        thresholds = {'good': 0.8, 'acceptable': 0.5}\n        if silhouette >= thresholds['good']:\n            return 'Good'\n        elif silhouette >= thresholds['acceptable']:\n            return 'Acceptable'\n        return 'Poor'\n    \n    try:\n        df['Quality'] = df['Silhouette'].apply(assign_quality_dynamic)\n        \n        # Encode categorical variables\n        le_method = LabelEncoder()\n        le_algorithm = LabelEncoder()\n        df['Method_Encoded'] = le_method.fit_transform(df['Method'])\n        df['Algorithm_Encoded'] = le_algorithm.fit_transform(df['Algorithm'])\n        \n        # Features: dataset characteristics + clustering metrics\n        features = ['n_traces', 'n_unique_activities', 'avg_trace_length', 'max_trace_length', 'num_events',\n                    'N_Clusters', 'Fitness', 'Simplicity', 'Precision', 'Generalization', 'Method_Encoded', 'Algorithm_Encoded']\n        X = df[features].to_numpy()\n        y = df['Quality'].to_numpy()\n        \n        # Handle NaN/infinite values\n        X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n        \n        # Standardize features\n        scaler = StandardScaler()\n        X_scaled = scaler.fit_transform(X)\n        \n        # Split data\n        try:\n            X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n        except ValueError as e:\n            print(f\"Error during train-test split: {e}\")\n            print(\"Falling back to non-stratified split...\")\n            X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n        \n        # Define neural network\n        model = Sequential([\n            Dense(64, activation='relu', input_shape=(len(features),)),\n            Dropout(0.2),\n            Dense(32, activation='relu'),\n            Dropout(0.2),\n            Dense(16, activation='relu'),\n            Dense(3, activation='softmax')  # 3 classes: Good, Acceptable, Poor\n        ])\n        \n        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n        \n        # Encode target\n        le_quality = LabelEncoder()\n        y_train_encoded = le_quality.fit_transform(y_train)\n        y_test_encoded = le_quality.transform(y_test)\n        \n        # Train model\n        model.fit(X_train, y_train_encoded, epochs=20, batch_size=32, validation_data=(X_test, y_test_encoded), verbose=1)\n        \n        # Evaluate\n        loss, accuracy = model.evaluate(X_test, y_test_encoded)\n        print(f\"Neural Network Test Accuracy: {accuracy:.4f}\")\n        \n        return model, scaler, le_method, le_algorithm, le_quality\n    except Exception as e:\n        print(f\"Error in train_neural_network: {e}\")\n        return None, None, None, None, None\n\ndef predict_best_combination(model, scaler, le_method, le_algorithm, le_quality, results_df):\n    \"\"\"Predict the best combination across all datasets.\"\"\"\n    if model is None:\n        print(\"Error: Neural network model not trained. Selecting best combination by Composite Score.\")\n        best_idx = results_df['Composite_Score'].idxmax()\n        return results_df.loc[best_idx]\n    \n    try:\n        df = results_df.copy()\n        df['Method_Encoded'] = le_method.transform(df['Method'])\n        df['Algorithm_Encoded'] = le_algorithm.transform(df['Algorithm'])\n        \n        # Features\n        features = ['n_traces', 'n_unique_activities', 'avg_trace_length', 'max_trace_length', 'num_events',\n                    'N_Clusters', 'Fitness', 'Simplicity', 'Precision', 'Generalization', 'Method_Encoded', 'Algorithm_Encoded']\n        X = df[features].to_numpy()\n        X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n        X_scaled = scaler.transform(X)\n        \n        # Predict\n        predictions = model.predict(X_scaled)\n        predicted_quality = le_quality.inverse_transform(np.argmax(predictions, axis=1))\n        df['Predicted_Quality'] = predicted_quality\n        \n        # Select best combination\n        good_combinations = df[df['Predicted_Quality'] == 'Good']\n        if len(good_combinations) == 0:\n            good_combinations = df[df['Predicted_Quality'] == 'Acceptable']\n        if len(good_combinations) == 0:\n            good_combinations = df\n        \n        best_combination_idx = good_combinations['Composite_Score'].idxmax()\n        best_combination = good_combinations.loc[best_combination_idx]\n        \n        return best_combination\n    except Exception as e:\n        print(f\"Error in predict_best_combination: {e}\")\n        best_idx = results_df['Composite_Score'].idxmax()\n        return results_df.loc[best_idx]\n\ndef main_part2():\n    \"\"\"Aggregate results from Part 1 and train neural network to find the best combination.\"\"\"\n    # Define the results directory\n    results_dir = \"/kaggle/input/results\"\n    \n    # Check if results directory exists\n    if not os.path.exists(results_dir):\n        print(f\"Results directory not found: {results_dir}\")\n        return\n    \n    # Aggregate results from all CSV files in the results directory\n    result_files = glob.glob(os.path.join(results_dir, \"results_*.csv\"))\n    if not result_files:\n        print(f\"No result files found in {results_dir}. Run Part 1 first.\")\n        return\n    \n    all_results = []\n    for file in result_files:\n        try:\n            df = pd.read_csv(file)\n            all_results.append(df)\n        except Exception as e:\n            print(f\"Error reading {file}: {e}\")\n            continue\n    \n    if not all_results:\n        print(\"No valid results to process.\")\n        return\n    \n    results_df = pd.concat(all_results, ignore_index=True)\n    results_df.to_csv('all_best_combinations_aggregated.csv', index=False)\n    print(\"Aggregated results saved to 'all_best_combinations_aggregated.csv'\")\n    \n    # Train neural network\n    model, scaler, le_method, le_algorithm, le_quality = train_neural_network(results_df)\n    \n    # Predict best combination\n    best_combination = predict_best_combination(model, scaler, le_method, le_algorithm, le_quality, results_df)\n    \n    # Output best combination\n    print(\"\\nOverall Best Clustering Combination Across All Datasets:\")\n    print(f\"Method: {best_combination['Method']}, Algorithm: {best_combination['Algorithm']}\")\n    print(f\"Predicted Quality: {best_combination['Predicted_Quality']}\")\n    print(f\"Metrics: Fitness={best_combination['Fitness']:.4f}, Simplicity={best_combination['Simplicity']:.4f}, \"\n          f\"Precision={best_combination['Precision']:.4f}, Generalization={best_combination['Generalization']:.4f}\")\n    print(f\"Silhouette Index: {best_combination['Silhouette']:.4f}, Composite Score: {best_combination['Composite_Score']:.4f}\")\n    \n    # Save final results\n    pd.DataFrame([best_combination]).to_csv('final_clustering_results.csv', index=False)\n    print(\"Final best combination saved to 'final_clustering_results.csv'\")\n\nif __name__ == \"__main__\":\n    main_part2()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-14T01:37:29.904619Z","iopub.execute_input":"2025-07-14T01:37:29.905121Z","iopub.status.idle":"2025-07-14T01:37:52.903749Z","shell.execute_reply.started":"2025-07-14T01:37:29.905091Z","shell.execute_reply":"2025-07-14T01:37:52.903130Z"}},"outputs":[{"name":"stderr","text":"2025-07-14 01:37:33.162223: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1752457053.350762      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1752457053.409901      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Aggregated results saved to 'all_best_combinations_aggregated.csv'\nTraining neural network...\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1752457065.535368      37 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1752457068.843656      96 service.cc:148] XLA service 0x7c7f1800b4f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1752457068.844449      96 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1752457069.091863      96 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.2727 - loss: 1.1374","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1752457070.602295      96 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.2727 - loss: 1.1374 - val_accuracy: 0.0000e+00 - val_loss: 1.2046\nEpoch 2/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.6364 - loss: 1.0132 - val_accuracy: 0.0000e+00 - val_loss: 1.1727\nEpoch 3/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3636 - loss: 1.0706 - val_accuracy: 0.0000e+00 - val_loss: 1.1419\nEpoch 4/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.4545 - loss: 1.0454 - val_accuracy: 0.0000e+00 - val_loss: 1.1092\nEpoch 5/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7273 - loss: 0.9420 - val_accuracy: 0.3333 - val_loss: 1.0743\nEpoch 6/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6364 - loss: 0.9428 - val_accuracy: 0.6667 - val_loss: 1.0411\nEpoch 7/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.8586 - val_accuracy: 0.6667 - val_loss: 1.0095\nEpoch 8/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.8182 - loss: 0.8256 - val_accuracy: 0.6667 - val_loss: 0.9812\nEpoch 9/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.8182 - loss: 0.8126 - val_accuracy: 0.6667 - val_loss: 0.9520\nEpoch 10/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9091 - loss: 0.7686 - val_accuracy: 0.6667 - val_loss: 0.9237\nEpoch 11/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9091 - loss: 0.7419 - val_accuracy: 0.6667 - val_loss: 0.8959\nEpoch 12/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 1.0000 - loss: 0.7641 - val_accuracy: 0.6667 - val_loss: 0.8692\nEpoch 13/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.6683 - val_accuracy: 0.6667 - val_loss: 0.8401\nEpoch 14/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.6353 - val_accuracy: 0.6667 - val_loss: 0.8111\nEpoch 15/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.6078 - val_accuracy: 0.6667 - val_loss: 0.7821\nEpoch 16/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.5523 - val_accuracy: 0.6667 - val_loss: 0.7520\nEpoch 17/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.5345 - val_accuracy: 1.0000 - val_loss: 0.7206\nEpoch 18/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.5392 - val_accuracy: 1.0000 - val_loss: 0.6889\nEpoch 19/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.5001 - val_accuracy: 1.0000 - val_loss: 0.6554\nEpoch 20/20\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.4431 - val_accuracy: 1.0000 - val_loss: 0.6213\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.6213\nNeural Network Test Accuracy: 1.0000\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step\n\nOverall Best Clustering Combination Across All Datasets:\nMethod: A3, Algorithm: DBSCAN\nPredicted Quality: Good\nMetrics: Fitness=0.9535, Simplicity=11.8788, Precision=1.0000, Generalization=0.7810\nSilhouette Index: 1.0000, Composite Score: 0.9978\nFinal best combination saved to 'final_clustering_results.csv'\n","output_type":"stream"}],"execution_count":1}]}